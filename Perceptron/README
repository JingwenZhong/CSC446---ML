CSC446 Machine Learning - HW 2

The training dataset contains 16100 individuals, and each individual has 123 features.

Train_ys looks like: array([-1, -1, -1, ...,  1, -1,  1])

Train_xs looks like: array([[0., 0., 1., ..., 0., 0., 1.],
                            [0., 0., 1., ..., 0., 0., 1.],
                            [0., 0., 1., ..., 0., 0., 1.],
                            ...,
                            [0., 0., 1., ..., 0., 0., 1.],
                            [0., 0., 0., ..., 0., 0., 1.],
                            [0., 0., 0., ..., 0., 0., 1.]])

The default times of iterations are 50, and the learning rate is 1.

The development dataset is used to test the performances and decide which classifier should be be taken and also avoid overfitting

In my code, I used two conditions:

When nodev is True(when it is provided), we don't use the development data, and we provide the iterations and learning rate by running something like Python ./Zhong_perceptron.py --nodev --iterations 1 --lr 1 on the terminal

When nodev is not provided, I use the development dataset. I let the Perceptron run 100*50 times, and use the weights to calculate both accuracy of trainning dataset and develpment dataset, and also conduct a graph for the performance of accuracy. I run Python ./Zhong_perceptron.py on the terminal.

From the graph, I found the performances of trainning set and the development set are very similar, I can't conclude anything from the graph, and no obvious evidence indicates the classfication is overfitting.

Besides, ss the iterations increases, the performance does not change a lot.
